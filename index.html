<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
  <style>
    .navA{
      display: inline-block;
      margin-right: 13px;
      font-size: 16px;
      font-weight: 700;
      color: #000;
      text-decoration: none;
      padding: 5px ;
      border: #000 1px solid;
    }
    .navA:hover{
      color: #fff;
      background-color: #000;
    }
  </style>

  <title>Yang Sui</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ys_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yang Sui | 隋阳</name>
              </p>

              <p>
                  Howdy! I'm a fourth year Ph.D. student at <a href="https://www.ece.rutgers.edu/" target=_blank> Department of Electrical and Computer Engineering, Rutgers University</a>, working on deep learning, machine learning and computer vision, advised by <a href="https://sites.google.com/site/boyuaneecs/" target=_blank>Prof. Bo Yuan</a>. I received my M.E. and B.E. at <a href="https://ee.jlu.edu.cn/" target=_blank>College of Electronic Science and Engineering, Jilin University</a>.
              </p>

              <p>
               During the 2023 Fall, I participated in the Princeton-Rutgers Exchange Program as a visiting student at <a href="https://www.cs.princeton.edu/" target=_blank>Princeton University</a>. From May 2022 to May 2023, I was a Research Intern at <a href="https://multimedia.tencent.com/" target=_blank>Media Lab, Tencent America</a>, exploring efficiency and robustness of Learned Image Compression and Transformer models. In 2019, I was a full-time Algorithm Engineer at <a href="https://corporate.jd.com/" target=_blank>JD</a>, working on the face verification and recognition. In 2018, I also spent a wonderful time as a Research and Development Intern and a member of <a href="https://github.com/PaddlePaddle/Paddle" target=_blank>PaddlePaddle</a> (<font color="#FF8166">20.4k stars now</font>), initializing the deep learning inference framework <a href="https://github.com/PaddlePaddle/Paddle-Lite" target=_blank>Paddle-Lite</a> (<font color="#FF8166">6.6k stars now</font>) at <a href="https://en.wikipedia.org/wiki/Baidu" target=_blank>Baidu</a>, reported in  <a href="https://nips.cc/Expo/Conferences/2019/Schedule?demo_id=21" target=_blank>NeurIPS Expo</a>, <a href=" https://create.baidu.com/" target=_blank>Baidu Create</a>, <a href="http://www.wavesummit.com.cn/#/" target=_blank> Wave Summit+</a>.
              </p>

<!--              <p>-->
<!--                I'm honored that will be joining <a href="https://corporate.jd.com/" target=_blank>Georgia Institute of Technology</a> as a PostDoc in 2024, continuing to work on efficient deep learning with <a href="https://sites.google.com/site/samanzonouz4n6/saman-zonouz">Prof. Saman Zonouz</a>. -->
<!--              </p>-->

              <p>
                In addition to my academic work, I am passionate about Basketball, DOTA/DOTA2, World of Warcraft. I love Tracy McGrady, Stephen Curry, Lionel Messi, PIS (YaphetS). Join me for a game of basketball anytime.
              </p>

              <p>
                I'm looking forward to the collaboration related to efficiency and security of deep learning. If you're interested in working with me, please don't hesitate to contact me.
              </p>

<!--              <p>-->
<!--                Xiaolan (name is inspired from "Detective Conan"), my adorable grey and white cat with sparkling eyes, which appears in my NeurIPS'21 paper "CHIP", is playful, affectionate, and loves to cuddle. Say hi, Xiaolan!-->
<!--              </p>-->

              <p style="text-align:center">
                <a href="mailto:ys764@scarletmail.rutgers.edu" target=_blank>Email</a> &nbsp/&nbsp
<!--                <a href="Yang_files/YangSui_CV.pdf" target=_blank>CV (Feb 2023)</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=Q2W1p6sAAAAJ&hl=en" target=_blank>Google Scholar</a> &nbsp/&nbsp
<!--                <a href="https://www.linkedin.com/in/yang-sui-308055117/" target=_blank>LinkedIn</a> &nbsp/&nbsp-->
                <a href="https://github.com/Eclipsess" target=_blank>Github</a> &nbsp&nbsp
              </p>
<!--              <p>-->
<!--                <b><font color="red">I'm actively looking for multiple PhDs / interns to work in Efficient & Reliable AI <a href="https://www.1point3acres.com/bbs/thread-936744-1-1.html">(一亩三分地 I,</a> <a href="https://www.1point3acres.com/bbs/thread-885798-1-1.html">一亩三分地 II)</a>. Feel free to send me your CV. Once we have a commitment to each other, trust me I will do my best to help you!</font></b> &nbsp&nbsp-->
<!--              </p>-->
<!--              <p>-->
<!--                <font color="blue"><em>(I've received a large number of applications. Super thanks for everyone's interest! Interviews are in progress. Good luck~)</em></font> &nbsp&nbsp-->
<!--              </p>-->


            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yangsui_cv.png" target=_blank><img style="width:80%;max-width:80%" alt="profile photo" src="images/yangsui_cv.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <div class="navbar" style="padding-left: 18px;">
          <a href="#Research" class="navA">Research</a>
          <a href="#News" class="navA">News</a>
          <a href="#Publications" class="navA">Publications</a>
          <a href="#Projects" class="navA">Projects</a>
          <a href="#Students" class="navA">Students</a>
          <a href="#Teaching" class="navA">Teaching</a>
          <a href="#Services" class="navA">Services</a>
<!--          <a href="#Patent" class="navA">Patents</a>-->
<!--          <a href="#Talks" class="navA">Talks</a>-->
          <a href="#Honors" class="navA">Awards</a>
<!--           <a href="#Extracurricular" class="navA">Extracurricular Activities</a> -->
        </div>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>

          <td width="100%" valign="middle">

            <heading id="Research"><b>Research Interests</b></heading>
<!--             <p>
            I am interested in efficient & reliable deep learning for AI at scale, investigating how to improve the efficiency of deep learning systems to achieve Pareto optimality between computing resources (e.g., parameter, data, computation) and model performance (e.g., inference, training). My long-term research goal is to free AI from the parameter-data-computation hungry beasts, and democratize AI to serve a broader area and population.
            </p> -->
            <p>
<!--            My research is primarily focused on two areas: Efficient AI and Secure AI. In the domain of Efficient AI, my investigations revolve around developing techniques to achieve resource-efficient deep learning models without compromising their accuracy or performance. I aim to design and innovate compression methods, such as pruning, quantization, and low-rank approximation, to reduce the size and complexity of deep learning models. By doing so, I intend to facilitate the deployment of these models on resource-constrained devices like mobile phones and embedded systems. This will expand the accessibility and practicality of deep learning in various real-world applications.-->
<!--            -->
<!--            In my research on Secure AI, my interests lie in adversarial attacks and backdoor attacks. I am dedicated to understanding the vulnerabilities of AI models in the face of these malicious threats. By investigating adversarial attacks, I aim to develop defense mechanisms that enhance the robustness and resilience of AI models against adversarial perturbations. Additionally, I focus on studying backdoor attacks to detect and mitigate hidden triggers and patterns that could compromise AI models. Through my research in Secure AI, I strive to contribute to the development of secure AI technologies that can withstand and mitigate potential attacks, ensuring the integrity and reliability of AI systems in different domains.-->
<!--            -->
<!--            Overall, my research endeavors aim to address the challenges in Efficient AI and Secure AI by developing innovative techniques, methodologies, and defense mechanisms. By pushing the boundaries of efficiency and security in AI, I aspire to advance the field and make valuable contributions to the broader landscape of artificial intelligence.-->



            My research is primarily focused on Efficient AI and Secure AI. In the domain of Efficient AI, my investigations revolve around developing techniques to achieve resource-efficient deep learning models without compromising their accuracy or performance. I aim to design and innovate compression methods, such as pruning, quantization, and low-rank approximation, to reduce the size and complexity of deep learning models. By doing so, I intend to facilitate the deployment of these models on resource-constrained devices like mobile phones and embedded systems.

            In my research on Secure AI, my interests lie in investigating the vulnerability and robustness through adversarial attacks and backdoor attacks. I am dedicated to understanding the vulnerabilities of AI models in the face of these malicious threats and develop defense mechanisms that enhance the robustness AI models against these attacks.

            Specifically, my research areas include:

            </p>

            Technologies:
            <ul>
            <li><p>
              AI Efficiency: Model Compression & Data Compression.
            </p>
            <li><p>
              AI Security: Model Vulnerability & Robustness.
            </p>
            <li><p>
              Algorithm-hardware Co-design for AI Acceleration.
            </p>
            </ul>
            Tasks:
            <ul>
            <li><p>
              Generative AI: Diffusion Model & Large Language Model.
            </p>
            <li><p>
              Supervised Learning on CNN and Transformer.
            </p>
            <li><p>
              Image Processing: Learned Image Compression.
            </p>
            <li><p>
              Digital Signal Processing: Error Correct Coding, Radio Frequency Neural Network.
            </p>

            </ul>
          </td>
        </tr>

        <tr>

          <td width="100%" valign="middle">

<!--            <heading><b><font color="red"><i>Welcome to Efficient Deep Learning Reading Group (EDLRG), Fall 2023</i></font></b> <br>-->
<!--              <a href="https://eclipsess.github.io/edlrg.github.io/" target=_blank> (EDLRG Website)</a><br>-->
<!--              <a href="https://zhuanlan.zhihu.com/p/601150600" target=_blank> (知乎link)</a></heading><br>-->

<!--            <p>-->
<!--                Are you interested in efficient deep learning but find it hard to keep up with the latest research? Join our Efficient Deep Learning Reading Group! Our group is focused on reading and discussing the most important and influential papers in deep learning, with a special emphasis on efficiency and practical applications.-->

<!--                By joining our group, you'll have the opportunity to:-->
<!--            </p>-->

<!--            <ul>-->
<!--                <li><p> Stay up-to-date with the latest research in efficient deep learning, without having to spend countless hours sifting through papers on your own.-->
<!--                </p>-->
<!--                <li><p> Engage in thoughtful and productive discussions with other deep learning enthusiasts, sharing your insights and learning from others.-->
<!--                </p>-->
<!--                <li><p> Develop a deeper understanding of the key concepts and techniques in deep learning, and how they can be applied in real-world scenarios.-->
<!--                </p>-->
<!--                <li><p> Connect with like-minded individuals and build meaningful relationships with friends who are also interested in related fields.-->
<!--                </p>-->
<!--            </ul>-->
<!--            <p>-->
<!--                <font color="#FF8166">Our group meets once a week via Zoom, and sessions typically run for 60 minutes every Sunday at 9PM (EST) since Spet 2023</font>. We welcome participants of all backgrounds and experience levels, as long as you have a basic understanding of deep learning fundamentals. To ensure a high-quality experience for all members, we do ask that you commit to attending regularly and actively participating in discussions.-->

<!--                If you're interested in joining our group, please fill out the application form on our website. We look forward to hearing from you!-->
<!--            </p>-->


          <h2><b>Previous "Efficient Deep Learning Reading Group" Sessions:</b></h2>
            <ul>
                <li><p> EDLRG, Spring 2023. Feb 2023 to May 2023. <a href="https://eclipsess.github.io/edlrg.github.io/" target=_blank> (EDLRG Website)</a>
                </p>
            </ul>

          </td>
        </tr>




        <tr>
          <td>
            <heading id="News"><b>News</b></heading>
              <div class="list scroll">
              <ul>
                <li>11/2023: One paper is accepted by Journal of Visual Communication and Image Representation (<b>JVCI</b>).</li>
                <li>10/2023: One paper is accepted by The International Symposium on High-Performance Computer Architecture (<b>HPCA 2024</b>).</li>
                <li>09/2023: One paper is accepted by IEEE/ACM International Conference on Computer-Aided Design (<b>ICCAD 2023</b>).</li>
                <li>07/2023: Invited to deliver a talk, "Efficient Diffusion Models and Large Language Models: Quantization, Pruning, and LoRA." (<a href="https://www.bilibili.com/video/BV1Sm4y177yE/" target=_blank>Video</a>)</li>
                <li>07/2023: One paper is accepted by <a href="https://conferences.sigcomm.org/sigcomm/2023/workshop-ems.html" target=_blank> SIGCOMM'23 EMS Workshop</a>.</li>
                <li>07/2023: One paper is accepted with <b>Spotlight presentation</b> at <a href="https://neuralcompression.github.io/workshop23" target=_blank> ICML'23 NCW Workshop</a>.</li>
                <li>06/2023: One paper is accepted by IEEE/RSJ International Conference on Intelligent Robots (<b>IROS 2023</b>).</li>
                <li>03/2023: One paper is accepted by The 50th International Symposium on Computer Architecture (<b>ISCA 2023</b>).</li>
                <li>02/2023: One paper is accepted by IEEE/ACM Design Automation Conference (<b>DAC 2023</b>).</li>
                <li>02/2023: One paper receives the <b>Best Paper Runner-Up Award</b> with <b>Oral</b> presentation at <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/" target=_blank>AAAI’23 DCAA Workshop</a>.</li>
<!--                <li>01/2023: I will start the Postdoc at Georgia Institute of Technology after graduation.</li>-->
                <li>11/2022: Two papers are accepted with <b>Oral</b> presentation by AAAI Conference on Artificial Intelligence (<b>AAAI 2023</b>).</li>
                <li>10/2022: Present a poster in <a href="https://www.zurich.ibm.com/thinklab/AIcomputesymposium.html" target=_blank>IBM IEEE CAS/EDS – 5th AI Compute Symposium</a> at IBM Thomas J Watson Research Center, Yorktown Heights, NY.</li>
                <li>05/2022: I’m glad to join the <b>Media Lab, Tencent America</b> as a Research Intern at Palo Alto, CA.</li>
                <li>03/2022: One paper is accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2022</b>).</li>
                <li>09/2021: One paper is accepted by Neural Information Processing Systems Conference (<b>NeurIPS 2021</b>).</li>
                <li>09/2021: One paper is accepted by IEEE/ACM International Conference on Computer-Aided Design (<b>ICCAD 2021</b>).</li>
                <li>03/2021: One paper is accepted by ACM International Symposium on Computer Architecture (<b>ISCA 2021</b>).</li>
                <li>02/2021: One paper was accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>).</li>
              </ul>
              </div>
          </td>
        </tr>
        </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading id="Publications"><b>Publications & Preprints</b></heading>
              <!-- <h3>Graduate</h3> -->
<!--               <p>
                I'm interested in computer vision, machine learning, optimization, and image processing.
                Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.
                Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h3>2024</h3>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/jvci2024.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Corner-to-Center Long-range Context Model for Efficient Learned Image Compression</papertitle>
              </a>
              <br>
              <b>Yang Sui</b>, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Bo Yuan, Zhenzhong Chen
              <br>
              <em><b>[JVCI]</b></em> <i>Journal of Visual Communication and Image Representation</i>
              <br>
<!--              <a href="https://openreview.net/pdf?id=38sgR7agFC" target=_blank>PDF</a>-->
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
<!--              <img src="paper_fig/jvci2024.png" alt="3DSP" width="160" height="120" style="border-style: none">-->
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>MOPED: Efficient Motion Planning Engine with Flexible Dimension Support</papertitle>
              </a>
              <br>
              Lingyi Huang, Yu Gong, <b>Yang Sui</b>, Xiao Zang, Bo Yuan
              <br>
              <em><b>[HPCA 2024]</b></em> <i>The International Symposium on High-Performance Computer Architecture</i>
              <br>
<!--              <a href="https://openreview.net/pdf?id=38sgR7agFC" target=_blank>PDF</a>-->
              <br>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h3>2023</h3>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/iccad23.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>In-Sensor Radio Frequency Computing for Energy-Efficient Intelligent Radar</papertitle>
              </a>
              <br>
              <b>Yang Sui</b>, Minning Zhu, Lingyi Huang, Chung-Tse Michael Wu, Bo Yuan
              <br>
              <em><b>[ICCAD 2023]</b></em> <i>IEEE/ACM International Conference on Computer-Aided Design</i>
              <br>
<!--              <a href="https://openreview.net/pdf?id=38sgR7agFC" target=_blank>PDF</a>-->
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/sigcomm23.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Learning-based Homography Matrix Optimization for Dual-fisheye Video Stitching</papertitle>
              </a>
              <br>
              Mufeng Zhu, <b>Yang Sui</b>, Bo Yuan, Yao Liu
              <br>
              <em><b>[SIGCOMM 2023 Workshop]</b></em> <i>ACM SIGCOMM Workshop on Emerging Multimedia Systems (EMS)</i>
              <br>
<!--              <a href="https://openreview.net/pdf?id=38sgR7agFC" target=_blank>PDF</a>-->
              <br>
              <a href="https://conferences.sigcomm.org/sigcomm/2023/workshop-ems.html" target=_blank>Website</a>
<!--              <p><font color="#FF8166">Spotlight</font></p>-->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/tencent3_attack_quality.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Reconstruction Distortion of Learned Image Compression with Imperceptible Perturbations</papertitle>
              </a>
              <br>
              <b>Yang Sui</b>, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen
              <br>
              <em><b>[ICML 2023 Workshop]</b></em> <i>Neural Compression: From Information Theory to Applications</i>
              <br>
              <a href="https://openreview.net/pdf?id=38sgR7agFC" target=_blank>PDF</a>
              <br>
              <a href="https://neuralcompression.github.io/workshop23" target=_blank>Website</a>
              <p><font color="#FF8166">Spotlight presentation</font></p>
            </td>
          </tr>

<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="paper_fig/sigcomm23.png" alt="3DSP" width="160" height="120" style="border-style: none">-->
<!--            </td>-->
<!--            <td width="75%" valign="middle">-->
<!--              <a id="3DSP">-->
<!--                <papertitle>Learning-based Homography Matrix Optimization for Dual-fisheye Video Stitching</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              Mufeng Zhu, <b>Yang Sui</b>, Bo Yuan, Yao Liu-->
<!--              <br>-->
<!--              <em><b>[SIGCOMM 2023 Workshop]</b></em> <i>ACM SIGCOMM Workshop on Emerging Multimedia Systems (EMS)</i>-->
<!--              <br>-->
<!--&lt;!&ndash;              <a href="https://dl.acm.org/doi/pdf/10.1145/3579371.3589103" target=_blank>PDF</a>&ndash;&gt;-->
<!--            </td>-->
<!--          </tr>-->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/iros23.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>DynGMP: Graph Neural Network-based Motion Planning in Unpredictable Dynamic Environments</papertitle>
              </a>
              <br>
              Wenjin Zhang, Xiao Zang, Lingyi Huang, <b>Yang Sui</b>, Jingjin Yu, Yingying Chen, Bo Yuan
              <br>
              <em><b>[IROS 2023]</b></em> <i>IEEE/RSJ International Conference on Intelligent Robots and Systems</i>
              <br>
<!--              <a href="https://dl.acm.org/doi/pdf/10.1145/3579371.3589103" target=_blank>PDF</a>-->
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/isca23.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>ETTE: Efficient Tensor-Train-based Computing Engine for Deep Neural Networks</papertitle>
              </a>
              <br>
              Yu Gong, Miao Yin, Lingyi Huang, Jinqi Xiao, <b>Yang Sui</b>, Chunhua Deng, Bo Yuan
              <br>
              <em><b>[ISCA 2023]</b></em> <i>The 50th International Symposium on Computer Architecture</i>
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3579371.3589103" target=_blank>PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/dac23.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>DSPIMM: Digital Sparse In-Memory Matrix Vector Multplier for Communication Applications</papertitle>
              </a>
              <br>
              Amitesh Sridharan, Fan Zhang, <b>Yang Sui</b>, Bo Yuan, Deliang Fan
              <br>
              <em><b>[DAC 2023]</b></em> <i>The 60th Design Automation Conference</i>
              <br>
              <a href="https://ieeexplore.ieee.org/document/10247829" target=_blank>PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23ws_cepd1.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Sparse and Low-rank Neural Networks with Hybrid Compression</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              <b>Yang Sui</b>, Wanzhao Yang, Miao Yin, Yu Gong, Bo Yuan
              <br>
              <em><b>[AAAI 2023 Workshop]</b></em> <i>DCAA, The First Workshop on DL-Hardware Co-Design for AI Acceleration</i>
              <br>
              <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/" target=_blank>Website</a>
              <br>
              <a href="paper_fig/runner-up.jpg" target=_blank>Award</a>
              <p><font color="#FF8166"> Best Paper Runner-Up Award</font></p>
            </td>
          </tr>

<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="paper_fig/aaai23ws_training1.png" alt="3DSP" width="160" height="120" style="border-style: none">-->
<!--            </td>-->
<!--            <td width="75%" valign="middle">-->
<!--              <a id="3DSP">-->
<!--                <papertitle>Training Low-Rank CNNs with Orthogonality From Scratch</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <b>Yang Sui</b>, Miao Yin, Bo Yuan-->
<!--              <br>-->
<!--              <em><b>[AAAI 2023 Workshop]</b></em> <i>DCAA, The First Workshop on DL-Hardware Co-Design for AI Acceleration</i>-->
<!--              <br>-->
<!--              <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/" target=_blank>Website</a>-->
<!--            </td>-->
<!--          </tr>-->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23_cstar1.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CSTAR: Towards Compact and STructured Deep Neural Networks with Adversarial Robustness</papertitle>
              </a>
              <br>
              Huy Phan, Miao Yin, <b>Yang Sui</b>, Bo Yuan, Saman Zonouz
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The 37th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/abs/2212.01957" target=_blank>PDF</a>
              <p><font color="#FF8166">Oral</font></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23_haloc1.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks</papertitle>
              </a>
              <br>
              Jinqi Xiao, Chengming Zhang, Yu Gong, Miao Yin, <b>Yang Sui</b>, Lizhi Xiang, Dingwen Tao, Bo Yuan
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The 37th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://eecs.wsu.edu/~dtao/paper/AAAI23-HALOC.pdf" target=_blank>PDF</a>
              <p><font color="#FF8166">Oral</font></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/iclr_cepd.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CEPD: Co-Exploring Pruning and Decomposition for Compact DNN Models</papertitle>
              </a>
              <br>
              <b>Yang Sui</b>, Wanzhao Yang, Miao Yin, Yu Gong, Bo Yuan
              <br>
              <em><b>[Preprint]</b></em> <i></i>
              <br>
              <a href="https://openreview.net/pdf?id=PrRWSVT2htx" target=_blank>PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/iclr_elrt.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>ELRT: Towards Efficient Low-Rank Training for Compact Neural Networks</papertitle>
              </a>
              <br>
              <b>Yang Sui</b>, Miao Yin, Wanzhao Yang, Yu Gong, Jinqi Xiao, Huy Phan, Ding Ding, Xiaozhong Xu, Shan Liu, Zhenzhong Chen, Bo Yuan
              <br>
              <em><b>[Preprint]</b></em> <i></i>
              <br>
              <a href="https://openreview.net/pdf?id=TC39w69m8bB" target=_blank>PDF</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h3>2022</h3>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/tc.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Algorithm and Hardware Co-Design of Energy-Efficient LSTM Networks for Video Recognition with Hierarchical Tucker Tensor Decomposition</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Yu Gong, Miao Yin, Lingyi Huang, Chunhua Deng, <b>Yang Sui</b>, Bo Yuan
              <br>
              <em><b>[arXiv]</b></em>
              <br>
              <a href="https://arxiv.org/abs/2212.02046" target=_blank>PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/cvpr22.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>HODEC: Towards Efficient High-Order DEcomposed Convolutional Neural Networks</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Miao Yin, <b>Yang Sui</b>, Wanzhao Yang, Xiao Zang, Yu Gong, Bo Yuan
              <br>
              <em><b>[CVPR 2022]</b></em> <i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.pdf" target=_blank>PDF</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h3>2021</h3>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/neurips21_chip1.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CHIP: CHannel Independence-based Pruning for Compact Neural Networks</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              <b>Yang Sui</b>, Miao Yin, Yi Xie, Huy Phan, Saman Zonouz, Bo Yuan
              <br>
              <em><b>[NeurIPS 2021]</b></em> <i>The 35th Conference on Neural Information Processing Systems</i>
              <br>
              <a href="https://arxiv.org/pdf/2110.13981" target=_blank>PDF</a>
<!--              <p> We for the first time identify and study the reliability problem of sparse training and find that sparse training exacerbates the over-confidence problem of DNNs. We then develop a new sparse training method, CigL, to produce more reliable sparse models, which can simultaneously maintain or even improve accuracy with only a slight increase in computational and storage burden.</p>-->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/iccad211.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Algorithm and Hardware Co-design for Deep Learning-powered Channel Decoder: A Case Study</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Boyang Zhang*, <b>Yang Sui*</b>, Lingyi Huang, Siyu Liao, Chunhua Deng, Bo Yuan
              <br>
              <em><b>[ICCAD 2021]</b></em> <i>The IEEE International Conference on Computer-Aided Design</i>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9643510" target=_blank>PDF</a>
<!--              <p> We for the first time identify and study the reliability problem of sparse training and find that sparse training exacerbates the over-confidence problem of DNNs. We then develop a new sparse training method, CigL, to produce more reliable sparse models, which can simultaneously maintain or even improve accuracy with only a slight increase in computational and storage burden.</p>-->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/isca211.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>GoSPA: An Energy-efficient High-performance Globally Optimized SParse Convolutional Neural Network Accelerator</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Chunhua Deng, <b>Yang Sui</b>, Siyu Liao, Xuehai Qian, Bo Yuan
              <br>
              <em><b>[ISCA 2021]</b></em> <i>The ACM/IEEE 48th Annual International Symposium on Computer Architecture</i>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9499915" target=_blank>PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/cvpr211.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Efficient Tensor Decomposition-Based DNN Model Compression With Optimization Framework</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Miao Yin, <b>Yang Sui</b>, Siyu Liao, Bo Yuan
              <br>
              <em><b>[CVPR 2021]</b></em> <i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>
              <br>
              <a href="https://arxiv.org/abs/2107.12422" target=_blank>PDF</a>
            </td>
          </tr>

    </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading id="Projects"><b>Projects</b></heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h3>2018</h3>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/paddle_mobile1.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Paddle-Lite (Paddle-Mobile)</papertitle>
              </a>
              <br>
              Initial contributor: <b>Yang Sui</b>, Ruilong Liu, Jiaying Zhao, Wang Liu, Yonghui Li.
              <br>
              <em><b>[Baidu]</b></em> <i>The authors contributed almost equally to this work.</i>
              <br>
              <a href="https://github.com/PaddlePaddle/Paddle-Lite" target=_blank>Paddle-Lite Github</a> (<font color="#FF8166">6.4k stars</font>)
              <p>Paddle-Lite is an updated version of Paddle-Mobile, an open-open source deep learning framework designed to make it easy to perform inference on mobile, embeded, and IoT devices. It is compatible with PaddlePaddle and pre-trained models from other sources, reported in  <a href="https://nips.cc/Expo/Conferences/2019/Schedule?demo_id=21" target=_blank>NeurIPS Expo</a>, <a href=" https://create.baidu.com/" target=_blank>Baidu Create</a>, <a href="http://www.wavesummit.com.cn/#/" target=_blank> Wave Summit+</a>.
              </p>
            </td>
          </tr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Services"><b>Professional Services</b></heading>

      <ul>
        <li>
          Workshop Chair:
            <ul>
              <li>
                Publicity Chair, <a href="https://ncsu-dk-lab.github.io/workshops/relkd@2023/" target=_blank>International Workshop on Resource-Efficient Learning for Knowledge Discovery (RelKD 2023) @ KDD 2023</a>
              </li>
            </ul>
        </li>
      </ul>

      <ul>
        <li>
          Program Committee Member and Reviewer:
            <ul>
              <li>
                NeurIPS'22, 23
              </li>
              <li>
                ICLR'24
              </li>
              <li>
                ICML'22, 23
              </li>
              <li>
                CVPR'22, 23, 24
              </li>
              <li>
                ICCV'23
              </li>
              <li>
                ECCV'22
              </li>
              <li>
                KDD'23
              </li>
              <li>
                AAAI'22, 23, 24
              </li>
              <li>
                IROS'23
              </li>
              <li>
                TNNLS
              </li>
              <li>
                SDM'24
              </li>
            </ul>
        </li>
      </ul>

<!--      <ul>-->
<!--        <li>-->
<!--          Journal Reviewer:-->
<!--            <ul>-->
<!--&lt;!&ndash;              <li>&ndash;&gt;-->
<!--&lt;!&ndash;                IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)&ndash;&gt;-->
<!--&lt;!&ndash;              </li>&ndash;&gt;-->
<!--              <li>-->
<!--                IEEE Transactions on Neural Networks and Learning Systems (TNNLS)-->
<!--              </li>-->

<!--            </ul>-->
<!--        </li>-->
<!--      </ul>-->



          </td>
        </tr>
        </table>




    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Teaching"><b>Teaching Experiences</b></heading>


        <ul>
          <li>
            Teaching Assistant at Rutgers University
                <ul>
                <li><p>
                14:332:351 - Programming Methodology II, Fall 2020<br>
                Instructor: <a href="https://sites.google.com/site/samanzonouz4n6/saman-zonouz" target=_blank>Prof. Saman Zonouz</a> &nbsp&nbsp <!-- <br> -->
                </p>
                <li><p>
                14:332:351 - Programming Methodology II, Fall 2023<br>
                Instructor: <a href="https://yaoliu-yl.github.io/" target=_blank>Prof. Yao Liu</a> &nbsp&nbsp <!-- <br> -->
                </p>
                </ul>

          </li>
        </ul>


          </td>
        </tr>
        </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Students"><b>Supervised Students</b></heading>

        <ul>
        <li><p>
        <a href="https://scholar.google.com/citations?user=HQw_pxwAAAAJ&hl=en" target=_blank>Wenjin Zhang</a>, Ph.D. at Rutgers University<br>
        Topic: Quantization in Model Compression<br>
        </p>

        <li><p>
        Justin Ding, Master student at Rutgers University<br>
        Topic: Pruning in Model Compression<br>
        </p>

        <li><p>
        Linqi Xiao, Master student at Rutgers University<br>
        Topic: Error Correct Coding<br>
        </p>

        <li><p>
        Srinihar Bondalapati, Master student at Rutgers University<br>
        Topic: Quantization in Model Compression<br>
        </p>

        <li><p>
        Yue Wang, Master student at Rutgers University<br>
        Topic: Dataset Distillation, Pruning in Model Compression<br>
        </p>

        <li><p>
        Veena Vrushi, Undergraduate student at Rutgers University<br>
        Topic: Deep Learning in "Project SUPER Research Program".<br>
        </p>

        <li><p>
        Vijay Maddila, Graduate student at Rutgers University<br>
        Topic: Large Language Models.<br>
        </p>

        <li><p>
        Ayan Patel, High school student at High Technology High School<br>
        Topic: Deep Learning.<br>
        </p>


        </ul>
        </td>
        </tr>
        </table>



<!--    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
<!--        <tr>-->
<!--          <td width="100%" valign="middle">-->
<!--            <heading id="Patent">Patent Applications</heading>-->

<!--      <ul>-->

<!--        <li><p>-->
<!--          <i>System and Method for Knowledge-Preserving Neural Network Pruning.</i> <br>-->
<!--          Enxu Yan, <strong>Dongkuan Xu</strong>, and Zhibin Xiao. <br>-->
<!--          U.S. Patent. 11,200,497. Dec. 2021-->
<!--        </p>-->
<!--        -->

<!--      </ul>-->

<!--          </td>-->
<!--        </tr>-->
<!--        </table>-->


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Talks"><b>Talks</b></heading>

			<ul>

                <li><p>
                Efficient Diffusion Models and Large Language Models: Quantization, Pruning, and LoRA. (<a href="https://www.bilibili.com/video/BV1Sm4y177yE/" target=_blank>Video</a>)<br>
                July, 2023.<br>
                </p>

			</ul>

          </td>
        </tr>
        </table>


		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Honors"><b>Honors & Awards</b></heading>

        <ul>
          <li>
            Doctor of Philosophy (Ph.D.)
              <ul>
<!--                <li>-->
<!--                  <b><font color="red">College of IST Award for Excellence in Teaching Support (top 2), 2019</font></b>-->
<!--                </li>-->
                <li>
                  <b>Best Paper Runner-Up Award</b> at <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/" target=_blank>DCAA Workshop</a> @ AAAI, 2023
                </li>

                <li>
                  <b>First Place</b> of Classification Track: Fair and Intelligent Embedded System Challenge in <a href="https://esweek.org/tiny-and-fair-ml-design/" target=_blank> Tiny and Fair ML Design Competition @ ESWEEK 2023</a>
                </li>

                <li>
                  <b>Sixth Place</b> of <a href=https://tinymlcontest.github.io/TinyML-Design-Contest-2023/Winners.html target=_blank> 2023 ACM/IEEE TinyML Design Contest at ICCAD </a>
                </li>
              </ul>
          </li>
        </ul>

        <ul>
          <li>
            Master of Science (M.E.)
              <ul>
                <li>
                  Graduate Student Academic Scholarship, 2018
                </li>
                <li>
                  Graduate Student Academic Scholarship, 2017
                </li>
              </ul>
          </li>
        </ul>

        <ul>
          <li>
            Bachelor of Engineering (B.E.)
              <ul>

              <li>
                  Postgraduate Recommendation (10% in EE at Jilin University), 2016
              </li>
              <li>
              Outstanding Graduates, 2016
              </li>
                <li>
                  Second Prize Scholarship, 2015
                </li>
                <li>
                  Second Prize Scholarship, 2014
                </li>
                <li>
                  Second Prize Scholarship, 2013
                </li>

              </ul>
          </li>
        </ul>


          </td>
        </tr>
        </table>


		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Hobbies"><b>Hobbies & Interests</b></heading>
<!---->
          <p>
            In addition to my academic work, I am a fan of Basketball, Soccer, Formula 1, Snooker. I love Tracy McGrady, Stephen Curry, Lionel Messi, PIS (YaphetS).
          </p>

          <p>
            I'm an experienced player of DOTA/DOTA2, World of Warcraft, Warcraft III, manipulating Druid (Balance Druid), DH (Havoc Demon Hunter) in WoW, and NE (Night Elf) in Warcraft III. I would like record some impressive moments:
          </p>

        <ul>

        <li>World top 10 DPS of Balance Druid with H4 (Flamebender Ka'graz) in Blackrock Foundry reported on WCL, World of Warcraft, 2015<br>
              </li>

        <li>Raid Leader for defeating the Heroic Highmaul Raid in the Warlords of Draenor, World of Warcraft, 2014
              <ul>
                <li>I gathered my fourteen friends and together we conquered the Heroic Highmaul raid. It was an incredibly impressive experience that we won't soon forget.
              </li>
              </ul>
        <li>Member of DOTA school team (1/5) in Jilin City No.1 High School, DOTA, 2011<br>
              </li>

          <li>Ladder Rank: 147, Hearthstone Legend, 2016<br>
          </li>

          <li>Ladder Rank: 698, Witch Doctor, Season 9, Diablo III, 2016<br>
          </li>
			</ul>

            <p>
            I derive great pleasure from listening to the music that owns wonderful rhythm, especially R&B, and classical music from Chopin, Bach, Paganini.
            </p>

            <p>
              Xiaolan (name is inspired from "Detective Conan"), my adorable grey and white cat with sparkling eyes, which appears in my NeurIPS'21 paper "CHIP", is playful, affectionate, and loves to cuddle. Say hi, Xiaolan!
            </p>

          </td>
        </tr>
        </table>

<!--         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
<!--          <tr>-->
<!--            <td>-->
<!--              <heading>Professional Services</heading>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->
<!--        <table width="100%" align="center" border="0" cellpadding="20"><tbody>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>-->
<!--              <br>-->
<!--              <br>-->
<!--              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="images/cs188.jpg" alt="cs188">-->
<!--            </td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>-->
<!--              <br>-->
<!--              <br>-->
<!--              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>-->
<!--              <br>-->
<!--              <br>-->
<!--              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table> &ndash;&gt;-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:0px">
              <br><hr width=80%>
              <p style="text-align:right;font-size:small;">
                *Last updated on 11/2023*
                <br>
                <a href="https://jonbarron.info/" target=_blank>Inspired by Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>