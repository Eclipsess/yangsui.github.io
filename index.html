<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
  <style>
    .navA{
      display: inline-block;
      margin-right: 13px;
      font-size: 16px;
      font-weight: 700;
      color: #000;
      text-decoration: none;
      padding: 5px ;
      border: #000 1px solid;
    }
    .navA:hover{
      color: #fff;
      background-color: #000;
    }
  </style>

  <title>Yang Sui</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ys_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yang Sui | 隋阳</name>
              </p>

              <p>
                  Howdy! I'm a fourth year Ph.D. student at <a href="https://www.ece.rutgers.edu/"> Rutgers University, ECE Department</a>, working on deep learning, machine learning and computer vision, advised by <a href="https://sites.google.com/site/boyuaneecs/">Prof. Bo Yuan</a>. I received my M.S. and B.E. at <a href="https://ee.jlu.edu.cn/">Jilin University</a>.
              </p>

              <p>
                I'm currently a Research Intern at <a href="https://multimedia.tencent.com/">Media Lab, Tencent America</a>, working with <a href="https://scholar.google.com/citations?user=6glC_iEAAAAJ&hl=en">Dr. Ding Ding</a>, <a href="https://scholar.google.com/citations?user=w_BcpK8AAAAJ&hl=en">Prof. Zhenzhong Chen</a> since 2022, exploring efficient neural image compression and Transformer models. In 2019, I was a full-time Algorithm Engineer at <a href="https://corporate.jd.com/">JD</a>, working on the face verification and recognition. I also spent a wonderful time as a Research and Development Intern, initializing the deep learning inference framework <a href="https://github.com/PaddlePaddle/Paddle-Lite">Paddle-Lite</a> (<font color="#FF8166">6.4k stars now</font>) at <a href="https://en.wikipedia.org/wiki/Baidu">Baidu</a> in 2018.
              </p>

              <p>
                I'm honored that will be joining <a href="https://corporate.jd.com/">Georgia Institute of Technology</a> as a PostDoc in 2024, continuing to work on efficient deep learning with <a href="https://sites.google.com/site/samanzonouz4n6/saman-zonouz">Prof. Saman Zonouz</a>. I'm really looking forward to the collaboration related to efficient deep learning. If you're interested in working with me, please don't hesitate to contact me.
              </p>

              <p>
                In addition to my academic work, I am passionate about Basketball, DOTA/DOTA2, World of Warcraft, Warcraft III. I am also a fan of Soccer, Formula 1, Snooker. I love Tracy McGrady, Stephen Curry, Lionel Messi, PIS (YaphetS). I'm an experienced player of Druid (Balance Druid), DH (Havoc Demon Hunter) in WoW, and NE (Night Elf) in Warcraft III. I derive great pleasure from listening to the music that owns wonderful rhythm, especially R&B, and classical music from Chopin, Bach, Paganini.
              </p>

              <p>
                Xiaolan (name is inspired from "Detective Conan"), my adorable grey and white cat with sparkling eyes, which appears in my NeurIPS'21 paper "CHIP", is playful, affectionate, and loves to cuddle. Say hi, Xiaolan!
              </p>

              <p style="text-align:center">
                <a href="mailto:ys764@scarletmail.rutgers.edu">Email</a> &nbsp/&nbsp
                <a href="Yang_files/YangSui_CV.pdf">CV (Feb 2023)</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Q2W1p6sAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/yang-sui-308055117/">LinkedIn</a> &nbsp&nbsp
              </p>
<!--              <p>-->
<!--                <b><font color="red">I'm actively looking for multiple PhDs / interns to work in Efficient & Reliable AI <a href="https://www.1point3acres.com/bbs/thread-936744-1-1.html">(一亩三分地 I,</a> <a href="https://www.1point3acres.com/bbs/thread-885798-1-1.html">一亩三分地 II)</a>. Feel free to send me your CV. Once we have a commitment to each other, trust me I will do my best to help you!</font></b> &nbsp&nbsp-->
<!--              </p>-->
<!--              <p>-->
<!--                <font color="blue"><em>(I've received a large number of applications. Super thanks for everyone's interest! Interviews are in progress. Good luck~)</em></font> &nbsp&nbsp-->
<!--              </p>-->


            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yangsui_cv.png"><img style="width:80%;max-width:80%" alt="profile photo" src="images/yangsui_cv.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <div class="navbar" style="padding-left: 18px;">
          <a href="#Research" class="navA">Research</a>
          <a href="#News" class="navA">News</a>
          <a href="#Publications" class="navA">Publications</a>
          <a href="#Students" class="navA">Students</a>
          <a href="#Teaching" class="navA">Teaching</a>
          <a href="#Services" class="navA">Services</a>
<!--          <a href="#Patent" class="navA">Patents</a>-->
<!--          <a href="#Talks" class="navA">Talks</a>-->
          <a href="#Honors" class="navA">Awards</a>
          <!-- <a href="#Extracurricular" class="navA">Extracurricular Activities</a> -->
        </div>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>

          <td width="100%" valign="middle">

            <heading id="Research"><b>Research</b></heading>
<!--             <p>
            I am interested in efficient & reliable deep learning for AI at scale, investigating how to improve the efficiency of deep learning systems to achieve Pareto optimality between computing resources (e.g., parameter, data, computation) and model performance (e.g., inference, training). My long-term research goal is to free AI from the parameter-data-computation hungry beasts, and democratize AI to serve a broader area and population.
            </p> -->
            <p>
            I'm interested in efficient deep learning, investigating how to optimize computational resources (e.g., parameters, data, computation) and model performance (e.g., inference, training).
            </p>

            <ul>
            <li><p>
              Efficient Training & Model Compression Algorithms
              <!-- Neural Architecture Search, Pruning, Knowledge Distillation -->
            </p>
            <li><p>
              Algorithm-hardware Co-design for AI Acceleration
              <!-- DeepLearning-hardware Co-design, Reduced-cost Training, Trainingless Proxies -->
            </p>
            <li><p>
              Efficient Vision Transformer
              <!-- DeepLearning-hardware Co-design, Reduced-cost Training, Trainingless Proxies -->
            </p>
            <li><p>
              Neural Image Compression
            </p>
            <li><p>
              Error Correct Coding
            </p>

            </ul>
          </td>
        </tr>

        <tr>

          <td width="100%" valign="middle">

            <heading><b><font color="red"><i>Welcome to join Efficient Deep Learning Reading Group (EDLRG)</i></font> <a href="https://zhuanlan.zhihu.com/p/601150600"> (知乎link)</a> </b></heading>
<!--            <p>-->
<!--            <font color="red"><b>Efficient Deep Learning Reading Group<a href="https://zhuanlan.zhihu.com/p/601150600">(知乎link)</a> </b></font>-->
<!--            </p>-->

            <p>
                Are you interested in efficient deep learning but find it hard to keep up with the latest research? Join our Efficient Deep Learning Reading Group! Our group is focused on reading and discussing the most important and influential papers in deep learning, with a special emphasis on efficiency and practical applications.

                By joining our group, you'll have the opportunity to:
            </p>

            <ul>
                <li><p> Stay up-to-date with the latest research in efficient deep learning, without having to spend countless hours sifting through papers on your own.
                </p>
                <li><p> Engage in thoughtful and productive discussions with other deep learning enthusiasts, sharing your insights and learning from others.
                </p>
                <li><p> Develop a deeper understanding of the key concepts and techniques in deep learning, and how they can be applied in real-world scenarios.
                </p>
                <li><p> Connect with like-minded individuals and build meaningful relationships with friends who are also interested in related fields.
                </p>
            </ul>
            <p>
                <font color="#FF8166">Our group meets once a week via Zoom, and sessions typically run for 60 minutes since Feb 25, 2023</font>. We welcome participants of all backgrounds and experience levels, as long as you have a basic understanding of deep learning fundamentals. To ensure a high-quality experience for all members, we do ask that you commit to attending regularly and actively participating in discussions.

                If you're interested in joining our group, please fill out the application form on our website. We look forward to hearing from you!
            </p>

          </td>
        </tr>

        <tr>
          <td>
            <heading id="News"><b>News</b></heading>
              <div class="list scroll">
              <ul>
                <li>02/2023: One paper is accepted by IEEE/ACM Design Automation Conference (<b>DAC 2023</b>).</li>
                <li>02/2023: One paper win the <b>Best Paper Runner-Up Award</b> at <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/">AAAI’23 DCAA Workshop</a> (<b>AAAI 2023</b>).</li>
<!--                <li>01/2023: I will start the Postdoc at Georgia Institute of Technology after graduation.</li>-->
                <li>11/2022: Two papers are accepted with oral presentation by AAAI Conference on Artificial Intelligence (<b>AAAI 2023</b>).</li>
                <li>10/2022: Present a poster in <a href="https://www.zurich.ibm.com/thinklab/AIcomputesymposium.html">IBM IEEE CAS/EDS – 5th AI Compute Symposium</a> at IBM Thomas J Watson Research Center, Yorktown Heights, NY.</li>
                <li>05/2022: I’m glad to join the <b>Media Lab, Tencent America</b> as a Research Intern at Palo Alto, CA.</li>
                <li>03/2022: One paper is accepted by IEEE/CVF Conf. on Computer Vision and Pattern Recognition (<b>CVPR 2022</b>).</li>
                <li>09/2021: One paper is accepted by Neural Information Processing Systems Conference (<b>NeurIPS 2021</b>).</li>
                <li>09/2021: One paper is accepted by IEEE/ACM Intl. Conf. on Computer Aided Design (<b>ICCAD 2021</b>).</li>
                <li>03/2021: One paper is accepted by ACM Intl. Symp. on Computer Architecture (<b>ISCA 2021</b>).</li>
                <li>02/2021: One paper was accepted by IEEE/CVF Conf. on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>).</li>
              </ul>
              </div>
          </td>
        </tr>
        </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading id="Publications"><b>Publications</b></heading>
              <!-- <h3>Graduate</h3> -->
<!--               <p>
                I'm interested in computer vision, machine learning, optimization, and image processing.
                Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.
                Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2023</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23ws_cepd.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Sparse and Low-rank Neural Networks with Hybrid Compression</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              <b>Yang Sui</b>, Wanzhao Yang, Miao Yin, Yu Gong, Bo Yuan
              <br>
              <em><b>[AAAI 2023 Workshop]</b></em> <i>DCAA, The First Workshop on DL-Hardware Co-Design for AI Acceleration</i>
              <br>
              <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/">Website</a>
              <p><font color="#FF8166"> Best Paper Runner-Up Award</font></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23ws_training.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Training Low-Rank CNNs with Orthogonality From Scratch</papertitle>
              </a>
              <br>
              <b>Yang Sui</b>, Miao Yin, Bo Yuan
              <br>
              <em><b>[AAAI 2023 Workshop]</b></em> <i>DCAA, The First Workshop on DL-Hardware Co-Design for AI Acceleration</i>
              <br>
              <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/">Website</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23_cstar.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CSTAR: Towards Compact and STructured Deep Neural Networks with Adversarial Robustness</papertitle>
              </a>
              <br>
              Huy Phan, Miao Yin, <b>Yang Sui</b>, Bo Yuan, Saman Zonouz
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The 37th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/abs/2212.01957">PDF</a>
              <p><font color="#FF8166">Oral</font></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/aaai23_haloc.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks</papertitle>
              </a>
              <br>
              Jinqi Xiao, Chengming Zhang, Yu Gong, Miao Yin, <b>Yang Sui</b>, Lizhi Xiang, Dingwen Tao, Bo Yuan
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The 37th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://eecs.wsu.edu/~dtao/paper/AAAI23-HALOC.pdf">PDF</a>
              <p><font color="#FF8166">Oral</font></p>
            </td>
          </tr>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2022</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/tc.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Algorithm and Hardware Co-Design of Energy-Efficient LSTM Networks for Video Recognition with Hierarchical Tucker Tensor Decomposition</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Yu Gong, Miao Yin, Lingyi Huang, Chunhua Deng, <b>Yang Sui</b>, Bo Yuan
              <br>
              <em><b>[IEEE TC]</b></em> <i>IEEE Transactions on Computers</i>
              <br>
              <a href="https://arxiv.org/abs/2212.02046">PDF</a>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/cvpr22.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>HODEC: Towards Efficient High-Order DEcomposed Convolutional Neural Networks</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Miao Yin, <b>Yang Sui</b>, Wanzhao Yang, Xiao Zang, Yu Gong, Bo Yuan
              <br>
              <em><b>[CVPR 2022]</b></em> <i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.pdf">PDF</a>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2021</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/neurips21_chip.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>CHIP: CHannel Independence-based Pruning for Compact Neural Networks</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              <b>Yang Sui</b>, Miao Yin, Yi Xie, Huy Phan, Saman Zonouz, Bo Yuan
              <br>
              <em><b>[NeurIPS 2021]</b></em> <i>The 35th Conference on Neural Information Processing Systems</i>
              <br>
              <a href="https://arxiv.org/pdf/2110.13981">PDF</a>
<!--              <p> We for the first time identify and study the reliability problem of sparse training and find that sparse training exacerbates the over-confidence problem of DNNs. We then develop a new sparse training method, CigL, to produce more reliable sparse models, which can simultaneously maintain or even improve accuracy with only a slight increase in computational and storage burden.</p>-->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/iccad21.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Algorithm and Hardware Co-design for Deep Learning-powered Channel Decoder: A Case Study</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Boyang Zhang*, <b>Yang Sui*</b>, Lingyi Huang, Siyu Liao, Chunhua Deng, Bo Yuan
              <br>
              <em><b>[ICCAD 2021]</b></em> <i>The IEEE International Conference on Computer-Aided Design</i>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9643510">PDF</a>
<!--              <p> We for the first time identify and study the reliability problem of sparse training and find that sparse training exacerbates the over-confidence problem of DNNs. We then develop a new sparse training method, CigL, to produce more reliable sparse models, which can simultaneously maintain or even improve accuracy with only a slight increase in computational and storage burden.</p>-->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/isca21.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>GoSPA: An Energy-efficient High-performance Globally Optimized SParse Convolutional Neural Network Accelerator</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Chunhua Deng, <b>Yang Sui</b>, Siyu Liao, Xuehai Qian, Bo Yuan
              <br>
              <em><b>[ISCA 2021]</b></em> <i>The ACM/IEEE 48th Annual International Symposium on Computer Architecture</i>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9499915">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="paper_fig/cvpr21.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Efficient Tensor Decomposition-Based DNN Model Compression With Optimization Framework</papertitle>
<!--                <papertitle><font color="red">CHIP: CHannel Independence-based Pruning for Compact Neural Networks</font></papertitle>-->
              </a>
              <br>
              Miao Yin, <b>Yang Sui</b>, Siyu Liao, Bo Yuan
              <br>
              <em><b>[CVPR 2021]</b></em> <i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>
              <br>
              <a href="https://arxiv.org/abs/2107.12422">PDF</a>
            </td>
          </tr>

    </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Services">Professional Services</heading>

      <ul>
        <li>
          <b>Program Committee Member:</b>
            <ul>
              <li>
                ICML'22, 23
              </li>
              <li>
                NeurIPS'22
              </li>
              <li>
                CVPR'22, 23
              </li>
              <li>
                ECCV'22
              </li>
              <li>
                AAAI'22, 23
              </li>
            </ul>
        </li>
      </ul>

      <ul>
        <li>
          <b>Journal Reviewer:</b>
            <ul>
<!--              <li>-->
<!--                IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)-->
<!--              </li>-->
<!--              <li>-->
<!--                Communications of the ACM-->
<!--              </li>-->
              <li>
                IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
              </li>
<!--              <li>-->
<!--                IEEE Transactions on Knowledge and Data Engineering (TKDE)-->
<!--              </li>-->
<!--              <li>-->
<!--                IEEE Transactions on Cybernetics-->
<!--              </li>-->
<!--              <li>-->
<!--                Information Fusion-->
<!--              </li>-->
<!--              <li>-->
<!--                ACM Transactions on Knowledge Discovery from Data (TKDD)-->
<!--              </li>-->
<!--              <li>-->
<!--                Pattern Recognition-->
<!--              </li>-->
<!--              <li>-->
<!--                Neural Networks-->
<!--              </li>-->
<!--              <li>-->
<!--                Neurocomputing-->
<!--              </li>-->
<!--              <li>-->
<!--                ACM Transactions on Asian and Low-Resource Language Information Processing-->
<!--              </li>-->
<!--              <li>-->
<!--                IEEE Access-->
<!--              </li>-->
<!--              <li>-->
<!--                Neural Computation-->
<!--              </li>-->
<!--              <li>-->
<!--                Complexity-->
<!--              </li>-->
<!--              <li>-->
<!--                Soft Computing-->
<!--              </li>-->
<!--              <li>-->
<!--                Complex & Intelligent Systems-->
<!--              </li>-->
<!--              <li>-->
<!--                Multimedia Tools and Applications-->
<!--              </li>-->
<!--              <li>-->
<!--                Big Data-->
<!--              </li>-->
            </ul>
        </li>
      </ul>



          </td>
        </tr>
        </table>




    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Teaching">Teaching Experiences</heading>


        <ul>
          <li>
            <b>Teaching Assistant at Rutgers University</b>

                <ul>
                <li><p>
                14:332:351 - Programming Methodology II, Fall 2020<br>
                Instructor: <a href="https://sites.google.com/site/samanzonouz4n6/saman-zonouz">Prof. Saman Zonouz</a> &nbsp&nbsp <!-- <br> -->
                </p>

                </ul>

          </li>
        </ul>


          </td>
        </tr>
        </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Students">Supervised Students</heading>

        <ul>
        <li><p>
        <a href="https://scholar.google.com/citations?user=HQw_pxwAAAAJ&hl=en">Wenjin Zhang</a>, Ph.D. at Rutgers University<br>
        Topic: Quantization, Model Compression<br>
        </p>

        <li><p>
        Justin Ding, Master at Rutgers University<br>
        Topic: Pruning, Model Compression<br>
        </p>

        <li><p>
        Linqi Xiao, Master at Rutgers University<br>
        Topic: Error Correct Coding, Channel Coding<br>
        </p>

        <li><p>
        Srinihar Bondalapati, Master at Rutgers University<br>
        Topic: Quantization, Model Compression<br>
        </p>

        <li><p>
        Yue Wang, Master at Rutgers University<br>
        Topic: Model Compression<br>
        </p>

        </ul>
        </td>
        </tr>
        </table>



<!--    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
<!--        <tr>-->
<!--          <td width="100%" valign="middle">-->
<!--            <heading id="Patent">Patent Applications</heading>-->

<!--      <ul>-->

<!--        <li><p>-->
<!--          <i>System and Method for Knowledge-Preserving Neural Network Pruning.</i> <br>-->
<!--          Enxu Yan, <strong>Dongkuan Xu</strong>, and Zhibin Xiao. <br>-->
<!--          U.S. Patent. 11,200,497. Dec. 2021-->
<!--        </p>-->
<!--        -->

<!--      </ul>-->

<!--          </td>-->
<!--        </tr>-->
<!--        </table>-->


<!--		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
<!--        <tr>-->
<!--          <td width="100%" valign="middle">-->
<!--            <heading id="Talks">Talks</heading>-->

<!--			<ul>-->

<!--                <li><p>-->
<!--                Parameter Efficiency: Democratizing AI at Scale (<a href="https://github.com/DerronXu/Talks/blob/master/Talk_Parameter_Efficiency_Democratize_AI_at_Scale_Brandeis.pdf">Slides</a>)<br>-->
<!--                Waltham, MA, USA, Dec. 2021.<br>-->
<!--                Brandeis University.-->
<!--                </p>-->
<!--              -->
<!--			</ul>-->

<!--          </td>-->
<!--        </tr>-->
<!--        </table>-->


		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Honors">Honors and Awards</heading>

        <ul>
          <li>
            <b>Doctor of Philosophy (Ph.D.)</b>
              <ul>
<!--                <li>-->
<!--                  <b><font color="red">College of IST Award for Excellence in Teaching Support (top 2), 2019</font></b>-->
<!--                </li>-->
                <li>
                  <b>Best Paper Runner-Up Award</b> at <a href="https://ncsu-dk-lab.github.io/workshops/dcaa@2023/">DCAA Workshop</a> @ AAAI, 2023
                </li>

              </ul>
          </li>
        </ul>

        <ul>
          <li>
            <b>Master of Science (M.S.)</b>
              <ul>
                <li>
                  Graduate Student Academic Scholarship, 2018
                </li>
                <li>
                  Graduate Student Academic Scholarship, 2017
                </li>
              </ul>
          </li>
        </ul>

        <ul>
          <li>
            <b>Bachelor of Engineering (B.E.)</b>
              <ul>

              <li>
                  <b>Postgraduate Recommendation (10% in EE at Jilin University)</b>, 2016
              </li>
              <li>
              Outstanding Graduates, 2016
              </li>
                <li>
                  Second Prize Scholarship, 2015
                </li>
                <li>
                  Second Prize Scholarship, 2014
                </li>
                <li>
                  Second Prize Scholarship, 2013
                </li>

              </ul>
          </li>
        </ul>

<!-- 				<ul>
        <li>NAACL Scholarship, 2021
        <br>
        <li>SIAM Student Travel Award, 2021
        <br>
        <li>IST Travel Award, 2021
        <br>
        <li>College of IST Award for Excellence in Teaching Support, Finalist, 2021
        <br>
				<li>KDD Student Registration Award, 2020
				<br>
				<li>AAAI Student Scholarship, 2020
				<br>
				<li>IST Travel Award, 2020
				<br>
				<li>IST Travel Award, 2019
				<br>
				<li>College of IST Award for Excellence in Teaching Support, 2019
				<br>
				<li>President's Fellowship of Chinese Academy of Sciences, 2016 <b>(1%)</b>
				<br>
				<li>National Graduate Scholarship, China, 2015 <b>(2%)</b>
				<br>
				<li>First-class Scholarship of Sashixuan Elite Fund, China, 2014 <b>(5%)</b>
				<br>
				<li>Kwang-hua Scholarship of RUC, China, 2014
				<br>
				<li>Second-class Scholarship of Excellent Student Cadre, 2014
				<br>
				<li>Meritorious Winner in Mathematical Contest in Modeling, USA, 2013
				<br>
				<li>First-class Scholarship of Social Work and Volunteer Service of RUC, 2013
				</ul> -->

          </td>
        </tr>
        </table>


		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading id="Extracurricular">Extracurricular Activities</heading>
<!---->
        <ul>

        <li>World Top 10 DPS of Balance Druid with H4 (Flamebender Ka'graz) in Blackrock Foundry reported on WCL, World of Warcraft, 2015<br>
              </li>

        <li>Raid Leader for defeating the Heroic Highmaul Raid in the Warlords of Draenor, World of Warcraft, 2014
              <ul>
                <li>I gathered my fourteen friends and together we conquered the Heroic Highmaul raid. It was an incredibly impressive experience that we won't soon forget.
              </li>
              </ul>
        <li>Member of DOTA team in Jilin City No.1 High School, 2011<br>
              </li>

			</ul>
<!---->
          </td>
        </tr>
        </table>
<!---->
<!--         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:0px">
              <br><hr width=80%>
              <p style="text-align:right;font-size:small;">
                *Last updated on 02/16/2023*
                <br>
                <a href="https://jonbarron.info/">Inspired by Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>